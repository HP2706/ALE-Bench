[build-system]
requires = ["hatchling", "uv-dynamic-versioning"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/ale_bench", "src/ale_bench_eval"]

[tool.hatch.version]
source = "uv-dynamic-versioning"

[project]
name = "ale_bench"
dynamic = ["version"]
description = "The official library for the ALE-Bench"
authors = [
    { name = "Yuki-Imajuku", email = "yuki.imjk@gmail.com" },
    { name = "Ino-Ichan", email = "sys.b11noway@gmail.com" },
]
readme = "README.md"
requires-python = ">=3.9,<3.15"
license = { file = "LICENSE" }
keywords = ["benchmark", "algorithmic programming", "atcoder", "AHC", "AI evaluation", "heuristic", "optimization", "estimation"]
classifiers = [
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Programming Language :: Python :: 3.14",
    "Development Status :: 5 - Production/Stable",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: Apache Software License",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
dependencies = [
    "ahocorapy",
    "cairosvg",
    "docker",
    "eval_type_backport; python_version == '3.9'",
    "huggingface_hub",
    "pillow",
    "polars>=1",
    "pydantic>=2",
    "typing_extensions",
]

[project.urls]
Repository = "https://github.com/SakanaAI/ALE-Bench"

[project.optional-dependencies]
dev = [
    "mypy==1.17.1",
    "pytest==8.4.2",
    "pytest-mock==3.15.0",
    "ruff==0.12.12",
    "types-requests==2.32.4.20250809",
]
eval = [
    "fire>=0.7.0",
    "genai-prices>=0.0.27",
    "numpy>=2.0.2",
    "pandas>=2.3.1",
    "psutil>=7.0.0",
    "pydantic-ai>=1.0.8; python_version >= '3.10'",
]

[tool.uv-dynamic-versioning]
fallback-version = "0.0.0"

[tool.mypy]
exclude = [
    "^src/ale_bench_eval/codes/.*\\.py$",
    "^tests/judge/codes/.*\\.py$",
]
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true
ignore_missing_imports = true

[tool.pytest.ini_options]
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "docker: marks tests as docker (deselect with '-m \"not docker\"')",
]

[tool.ruff]
extend-exclude = [
    "mcp",
    "src/ale_bench_eval/codes",
    "src/ale_bench_eval/prompts/texts.py",
    "tests/judge/codes",
]
fix = true
target-version = "py312"
line-length = 120

[tool.ruff.format]
quote-style = "double"

[tool.ruff.lint]
select = [
    "C9",
    "E",
    "F",
    "W",
    "I",
]
ignore = ["C901"]

[tool.ruff.lint.isort]
case-sensitive = true
combine-as-imports = true
default-section = "third-party"
known-first-party = [
    "ale_bench",
    "ale_bench_eval"
]
section-order = [
    "future",
    "standard-library",
    "third-party",
    "first-party",
    "local-folder"
]
split-on-trailing-comma = true
